\section{Related Work \label{RelatedWork} }
As mentioned above, self-supervised learning is about creating a supervisory signal to learn representations of data automatically or automatically create labels for a dataset. This chapter refers to projects related to self-supervised learning and provides detailed information about papers that cover robotics.\\

Self-supervised learning is used in many different fields of machine learning, like Representation Learning \cite{lee2020predicting,wang2020selfsupervised},Reeinforcement Learning \cite{xin2020selfsupervised}, Natural Language Processing \cite{meng2019selfsupervised}, Neural Networks \cite{wang2020selfsupervised,kundu2020appearance,harley2020tracking,luo2020exploring}, Generative Adversarial Networks \cite{mahapatra2020structure} and Robotics \cite{vibrationBasedLearning,nava2019learning,5979661,roboOverhead,Dahlkamp-RSS-06,932633,godard2018digging,hecke2016persistent,g2017learning} which this project is related to. \\

\cite{nava2019learning} provides the most similar concepts to this Bachelor thesis. The paper describes how to use short-range bumpers and relate them to long-range input, like images from a camera. The implementation presents a self-made robot \cite{mightyThymio}, designed for University-level educational purposes. The paper also presents a simulated performance with a Pioneer 3-AT platform in Gazebo, equipped with three cameras and a short-range sensor observing the floor's color below the robot.\\

\cite{5979661} presents an obstacle detection mechanism for humanoid navigation. The paper states that solely relying on laser range data can be problematic. The humanoid robot's sensors are located on the head, unable to recognize obstacles right in front of it. Their solution is to complement a monocular vision, located on the robot's head, with a 3-dimensional laser to create traversability labels. The paper concludes that better and more efficient navigation, a broader field of view, reduced travel time, and better performance in dealing with changes in the scene, is possible. As limitations, the authors claim, that moving obstacles or obstacles with a similar floor color can be problematic.\\

\cite{Dahlkamp-RSS-06} is also about an obstacle avoidance controller that uses a laser and a camera system as an additional long-range sensor. The implementation was presented in 2005, leading to the DARPA Grand Challenge win, a competition for autonomous vehicles, funded by the Defense Advanced Research Projects Agency. This project aimed to detect drivable surfaces in desert terrain, which is even more challenging than highways or paved roads in urban areas. The paper describes a novel algorithm that can adapt itself to different terrain types based on a self-supervised mechanism. Camera images are related to a short-range laser, responsible for scanning the vehicle's vicinity. A vision algorithm then creates a drivability map for up to 70 meters.\\

\cite{hecke2016persistent} proposes a self-supervised implementation from stereo to the monocular vision for obstacle avoidance. Their goal is to have a drone safely maneuver in a 5 X 5 m room to avoid obstacles. As a complementary sensor to monocular vision, the paper proposes a stereo-based distance estimation. This project's main challenges are to gather sufficient data for training and provide high performance in unknown environments. The article further compares its self-supervised approach to reinforcement learning, learning from demonstration, supervised learning and, unsupervised learning approaches.\\

\cite{godard2018digging} is about self-supervised monocular depth estimation. The authors provide a method that aims to create depth maps with a relatively simple model, comparing them to other self-supervised implementations, which deal with similar goals. The paper claims the results to be state-of-the-art with three main contributions introduced. Minimizing the reprojection loss corresponding to image distances between a projected and a measured point, an auto-masking loss to ignore confusion, and a multi-scale sampling method. The paper proposes that its contributions, in combination, provide an efficient model for depth estimation, trained with monocular video data, stereo data, or both combined.\\

\cite{vibrationBasedLearning} proposes a self-supervised implementation for planetary rovers. Their classification approach is about learning the visual appearance of terrain by relying on vibration-based sensing of wheel-terrain interaction. The goal is to recognize regular obstacles like rocks and cliffs and non-geometric hazards like loose sand, for example. The paper demonstrates that the self-supervised classifier should be preferred over manually trained classifiers, especially if the environment's illumination change would be faster than the manual classifier's retraining. The general performance in comparison against manual classifiers, which work on outdoor Mars-analog data sets, was shown to be as nearly as good.\\

\cite{roboOverhead} presents an implementation, including overhead imagery, to increase performance for uncrewed ground vehicles to allow them to traverse varied terrains safely. The authors claim that sensor data is often challenging to wildly take advantage of when generalizing to new environments and conditions. Overhead information is solving many problems related to autonomous robots for even the most challenging terrains due to the paper. The challenge is to properly interpret overhead data and correctly calibrate them with on-board predictions of the landscape. Similar as in the previously mentioned papers, this paper also uses several data sources and additionally self-supervised online learning to achieve a powerful long-range navigation mechanism.\\

\cite{g2017learning} describes a self-supervised technique for an unmanned aerial vehicle obstacle avoidance algorithm. The core of this approach is to combine a crash dataset in conjunction with positive data to learn a policy for navigation. The authors claim that simulation very often cannot properly transfer to real-world environments and therefore avoid it at all. The results of this project show that their implementation is effectively navigating even in cluttered environments with dynamic obstacles. The paper proposes a standard deep network architecture to train the datasets mentioned above. The article furthermore claims to outperform depth prediction based methods in several environments.